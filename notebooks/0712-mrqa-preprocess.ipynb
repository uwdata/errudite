{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context = '[DOC] [TLE] J! Archive - Show #5243, aired 2007-05-30 [PAR] May 30, 2007 ... 1976: \"A Single Colorado Mountain\". $1200, 19. Founded in the 1530s, this \\ncapital of Jalisco state is the second-largest in Mexico. $1200, 23... [DOC] [TLE] November 14, 2008 [PAR] ... \"Regular Folks\" Ordinary People 1932: \"Magnificent Inn\" Grand Hotel 1976: \"A \\nSingle Colorado Mountain\" Rocky Down Mexico Way: In 1986 Mexico scored... [DOC] [TLE] LAND USE AND LANDSCAPE CHANGE IN THE COLORADO ... [PAR] ... landscape change in a single Colorado mountain valley using methods from \\n..... and for multi-family 1970 1973 1976 1979 1982 1985 1988 1991 complexes... [DOC] [TLE] J! set #1 Flashcards | Quizlet [PAR] 18 shows included Learn with flashcards, games, and more  for free. '\n",
    "\n",
    "from errudite.processor import SpacyAnnotator\n",
    "spacy_annotator = SpacyAnnotator(disable=['parser', 'ner', 'textcat'])\n",
    "list(spacy_annotator.process_text(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "import errudite\n",
    "from errudite.io import DatasetReader\n",
    "from errudite.predictors import Predictor\n",
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.label import Label\n",
    "from errudite.utils import accuracy_score, normalize_file_path\n",
    "\n",
    "DATASET_FOLDER = normalize_file_path(\"~/datasets/raw_data/mrqa/out_of_domain_devs\")\n",
    "sample_size=100000\n",
    "file_path = \",\".join(glob.glob(os.path.join(DATASET_FOLDER, \"*.jsonl.gz\")))\n",
    "reader = DatasetReader.by_name(\"mrqa\")(\n",
    "    cache_folder_path=f\"~/datasets/caches/dataset_debug/mrqa-{sample_size}\")\n",
    "instances = reader.read(file_path, sample_size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "def import_sys():\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    sys.path.append('../..')\n",
    "import_sys()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalidzx-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:errudite.utils.file_utils:Local path not yet exist, but still parsed: /Users/tongshuangwu/sourcetree/errudite_dataset_debug/notebooks/caches/vocab.pkl\n",
      "WARNING:errudite.processor.spacy_annotator:(2, 'No such file or directory')\n",
      "INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "INFO:errudite.utils.file_utils:Errudite cache folder selected: /Users/tongshuangwu/datasets/caches/dataset_debug/mrqa-10\n",
      "INFO:errudite.io.dataset_reader:Reading instances from lines in file at: /Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/DuoRC.jsonl.gz\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: DuoRC.ParaphraseRC (out).\n",
      "1it [00:00,  3.37it/s]\n",
      "WARNING:errudite.utils.file_utils:Local path not yet exist, but still parsed: /Users/tongshuangwu/datasets/caches/dataset_debug/mrqa-10/vocab.pkl\n",
      "WARNING:errudite.processor.spacy_annotator:(2, 'No such file or directory')\n",
      "INFO:allennlp.models.archival:loading archive file /Users/tongshuangwu/datasets/models/mrqa/mrqa_bert_base.gz\n",
      "INFO:allennlp.models.archival:extracting archive file /Users/tongshuangwu/datasets/models/mrqa/mrqa_bert_base.gz to temp dir /var/folders/9k/yx4ryhp918qfxx59mmp174lh0000gn/T/tmp39qa6s5q\n",
      "INFO:allennlp.common.params:type = default\n",
      "INFO:allennlp.data.vocabulary:Loading token dictionary from /var/folders/9k/yx4ryhp918qfxx59mmp174lh0000gn/T/tmp39qa6s5q/vocabulary.\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.models.model.Model'> from params {'initializer': [], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'}}}, 'type': 'BERT_QA'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.type = BERT_QA\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'errudite.predictors.qa.mrqa_allennlp.BERT_QA.BERT_QA'> from params {'initializer': [], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'}}}} and extras {'vocab'}\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'}}} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.type = basic\n",
      "INFO:allennlp.common.params:model.text_field_embedder.allow_unmatched_keys = True\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.type = bert-pretrained\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': True} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-uncased\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.requires_grad = True\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.top_layer_only = False\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/tongshuangwu/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/tongshuangwu/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/9k/yx4ryhp918qfxx59mmp174lh0000gn/T/tmpa5tshfj2\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "import errudite\n",
    "from errudite.io import DatasetReader\n",
    "from errudite.predictors import Predictor\n",
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.label import Label\n",
    "from errudite.utils import accuracy_score, normalize_file_path\n",
    "\n",
    "DATASET_FOLDER = normalize_file_path(\"~/datasets/raw_data/mrqa/in_domain_devs\")\n",
    "sample_size=10\n",
    "file_path = \",\".join(glob.glob(os.path.join(DATASET_FOLDER, \"*.jsonl.gz\")))\n",
    "reader = DatasetReader.by_name(\"mrqa\")(\n",
    "    cache_folder_path=f\"~/datasets/caches/dataset_debug/mrqa-{sample_size}\")\n",
    "instances = reader.read(file_path, sample_size=sample_size)\n",
    "\n",
    "MODEL_FOLDER = normalize_file_path(\"~/datasets/models/mrqa/\")\n",
    "predictor = Predictor.by_name(\"mrqa\")(\n",
    "    name=\"mrqa_path\", \n",
    "    model_path=os.path.join(MODEL_FOLDER, \"mrqa_bert_base.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running predictions....\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]WARNING:allennlp.models.model:Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      " 10%|█         | 1/10 [00:12<01:53, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'acid', 'qid': 'tmp', 'best_span_logit': 8.56551742553711, 'char_offsets': [2476, 2480]}, {'best_span_str': 'acid', 'qid': 'tmp', 'best_span_logit': 8.56551742553711, 'char_offsets': [2476, 2480]}, {'best_span_str': 'acid', 'qid': 'tmp', 'best_span_logit': 8.56551742553711, 'char_offsets': [2476, 2480]}, {'best_span_str': 'acid', 'qid': 'tmp', 'best_span_logit': 8.56551742553711, 'char_offsets': [2476, 2480]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:27<01:46, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': '1927', 'qid': 'tmp', 'best_span_logit': 10.251514434814453, 'char_offsets': [26, 30]}, {'best_span_str': '1927', 'qid': 'tmp', 'best_span_logit': 10.251514434814453, 'char_offsets': [26, 30]}, {'best_span_str': '1927', 'qid': 'tmp', 'best_span_logit': 10.251514434814453, 'char_offsets': [26, 30]}, {'best_span_str': '1927', 'qid': 'tmp', 'best_span_logit': 10.251514434814453, 'char_offsets': [26, 30]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:42<01:35, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 7.422807693481445, 'char_offsets': [2083, 2090]}, {'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 7.422807693481445, 'char_offsets': [2083, 2090]}, {'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 7.422807693481445, 'char_offsets': [2083, 2090]}, {'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 7.422807693481445, 'char_offsets': [2083, 2090]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:56<01:23, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'Jill', 'qid': 'tmp', 'best_span_logit': 10.019155502319336, 'char_offsets': [2348, 2352]}, {'best_span_str': 'Jill', 'qid': 'tmp', 'best_span_logit': 10.019155502319336, 'char_offsets': [2348, 2352]}, {'best_span_str': 'Jill', 'qid': 'tmp', 'best_span_logit': 10.019155502319336, 'char_offsets': [2348, 2352]}, {'best_span_str': 'Jill', 'qid': 'tmp', 'best_span_logit': 10.019155502319336, 'char_offsets': [2348, 2352]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:11<01:10, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 6.424346923828125, 'char_offsets': [3113, 3120]}, {'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 6.424346923828125, 'char_offsets': [3113, 3120]}, {'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 6.424346923828125, 'char_offsets': [3113, 3120]}, {'best_span_str': 'Schweik', 'qid': 'tmp', 'best_span_logit': 6.424346923828125, 'char_offsets': [3113, 3120]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:25<00:56, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': '36', 'qid': 'tmp', 'best_span_logit': 10.423604965209961, 'char_offsets': [3804, 3806]}, {'best_span_str': '36', 'qid': 'tmp', 'best_span_logit': 10.423604965209961, 'char_offsets': [3804, 3806]}, {'best_span_str': '36', 'qid': 'tmp', 'best_span_logit': 10.423604965209961, 'char_offsets': [3804, 3806]}, {'best_span_str': '36', 'qid': 'tmp', 'best_span_logit': 10.423604965209961, 'char_offsets': [3804, 3806]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:37<00:40, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'Liza Merril', 'qid': 'tmp', 'best_span_logit': 12.780729293823242, 'char_offsets': [472, 483]}, {'best_span_str': 'Liza Merril', 'qid': 'tmp', 'best_span_logit': 12.780729293823242, 'char_offsets': [472, 483]}, {'best_span_str': 'Liza Merril', 'qid': 'tmp', 'best_span_logit': 12.780729293823242, 'char_offsets': [472, 483]}, {'best_span_str': 'Liza Merril', 'qid': 'tmp', 'best_span_logit': 12.780729293823242, 'char_offsets': [472, 483]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:50<00:26, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'Wart', 'qid': 'tmp', 'best_span_logit': 7.729559898376465, 'char_offsets': [658, 662]}, {'best_span_str': 'Wart', 'qid': 'tmp', 'best_span_logit': 7.729559898376465, 'char_offsets': [658, 662]}, {'best_span_str': 'Wart', 'qid': 'tmp', 'best_span_logit': 7.729559898376465, 'char_offsets': [658, 662]}, {'best_span_str': 'Wart', 'qid': 'tmp', 'best_span_logit': 7.729559898376465, 'char_offsets': [658, 662]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:02<00:12, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'Sir Pelinore', 'qid': 'tmp', 'best_span_logit': 8.468249320983887, 'char_offsets': [1464, 1476]}, {'best_span_str': 'Sir Pelinore', 'qid': 'tmp', 'best_span_logit': 8.468249320983887, 'char_offsets': [1464, 1476]}, {'best_span_str': 'Sir Pelinore', 'qid': 'tmp', 'best_span_logit': 8.468249320983887, 'char_offsets': [1464, 1476]}, {'best_span_str': 'Sir Pelinore', 'qid': 'tmp', 'best_span_logit': 8.468249320983887, 'char_offsets': [1464, 1476]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:13<00:00, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'best_span_str': 'London town', 'qid': 'tmp', 'best_span_logit': 7.203769683837891, 'char_offsets': [221, 232]}, {'best_span_str': 'London town', 'qid': 'tmp', 'best_span_logit': 7.203769683837891, 'char_offsets': [221, 232]}, {'best_span_str': 'London town', 'qid': 'tmp', 'best_span_logit': 7.203769683837891, 'char_offsets': [221, 232]}, {'best_span_str': 'London town', 'qid': 'tmp', 'best_span_logit': 7.203769683837891, 'char_offsets': [221, 232]}]\n",
      "         f1  predictor\n",
      "0  0.557143  mrqa_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({InstanceKey(qid='d94a42693350473581ff79dc91c91e04', vid=0): Instance [InstanceKey(qid='d94a42693350473581ff79dc91c91e04', vid=0)],\n",
       "  InstanceKey(qid='f41dbe24bed44870a8ad36c87dda59a2', vid=0): Instance [InstanceKey(qid='f41dbe24bed44870a8ad36c87dda59a2', vid=0)],\n",
       "  InstanceKey(qid='34f8093a16b64c8097bdaa03cccdef37', vid=0): Instance [InstanceKey(qid='34f8093a16b64c8097bdaa03cccdef37', vid=0)],\n",
       "  InstanceKey(qid='b6a13cac6289435697e8ff98d55854a9', vid=0): Instance [InstanceKey(qid='b6a13cac6289435697e8ff98d55854a9', vid=0)],\n",
       "  InstanceKey(qid='52ffe790d24a41669c08a240c1d45114', vid=0): Instance [InstanceKey(qid='52ffe790d24a41669c08a240c1d45114', vid=0)],\n",
       "  InstanceKey(qid='d0d647812b8d47e88327e05abd34c492', vid=0): Instance [InstanceKey(qid='d0d647812b8d47e88327e05abd34c492', vid=0)],\n",
       "  InstanceKey(qid='5e54f1fb51b34d5c91636ca9a1d3518a', vid=0): Instance [InstanceKey(qid='5e54f1fb51b34d5c91636ca9a1d3518a', vid=0)],\n",
       "  InstanceKey(qid='ee477db3268c4a0b8321e3cb971573a7', vid=0): Instance [InstanceKey(qid='ee477db3268c4a0b8321e3cb971573a7', vid=0)],\n",
       "  InstanceKey(qid='14f31e741dc847f99fc5459cbfeb82aa', vid=0): Instance [InstanceKey(qid='14f31e741dc847f99fc5459cbfeb82aa', vid=0)],\n",
       "  InstanceKey(qid='3dd25b201f7a4c57b12fe60dfd5f0c45', vid=0): Instance [InstanceKey(qid='3dd25b201f7a4c57b12fe60dfd5f0c45', vid=0)]},\n",
       " {},\n",
       " defaultdict(list,\n",
       "             {'14f31e741dc847f99fc5459cbfeb82aa': [InstanceKey(qid='14f31e741dc847f99fc5459cbfeb82aa', vid=0)],\n",
       "              '34f8093a16b64c8097bdaa03cccdef37': [InstanceKey(qid='34f8093a16b64c8097bdaa03cccdef37', vid=0)],\n",
       "              '3dd25b201f7a4c57b12fe60dfd5f0c45': [InstanceKey(qid='3dd25b201f7a4c57b12fe60dfd5f0c45', vid=0)],\n",
       "              '52ffe790d24a41669c08a240c1d45114': [InstanceKey(qid='52ffe790d24a41669c08a240c1d45114', vid=0)],\n",
       "              '5e54f1fb51b34d5c91636ca9a1d3518a': [InstanceKey(qid='5e54f1fb51b34d5c91636ca9a1d3518a', vid=0)],\n",
       "              'b6a13cac6289435697e8ff98d55854a9': [InstanceKey(qid='b6a13cac6289435697e8ff98d55854a9', vid=0)],\n",
       "              'd0d647812b8d47e88327e05abd34c492': [InstanceKey(qid='d0d647812b8d47e88327e05abd34c492', vid=0)],\n",
       "              'd94a42693350473581ff79dc91c91e04': [InstanceKey(qid='d94a42693350473581ff79dc91c91e04', vid=0)],\n",
       "              'ee477db3268c4a0b8321e3cb971573a7': [InstanceKey(qid='ee477db3268c4a0b8321e3cb971573a7', vid=0)],\n",
       "              'f41dbe24bed44870a8ad36c87dda59a2': [InstanceKey(qid='f41dbe24bed44870a8ad36c87dda59a2', vid=0)]}))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "predictors = { p.name: p for p in [predictor] }\n",
    "predictions = { p: [] for p in predictors }\n",
    "logger.info(\"Running predictions....\")\n",
    "for instance in tqdm(instances):\n",
    "    instance_predictions = []\n",
    "    for predictor in predictors.values():\n",
    "        prediction = Predictor.by_name(\"qa_task_class\").model_predict(\n",
    "            predictor, \n",
    "            instance.question, \n",
    "            instance.context, \n",
    "            instance.groundtruths)\n",
    "        instance_predictions.append(prediction)\n",
    "        #print(prediction.doc, prediction.span_start, prediction.span_end, instance.context)\n",
    "        predictions[predictor.name].append(prediction)\n",
    "    instance.set_entries(predictions=instance_predictions)\n",
    "for predictor in predictors.values():\n",
    "    predictor.evaluate_performance(instances)\n",
    "print(pd.DataFrame([ {\"predictor\": p.name, \"f1\": p.perform[\"f1\"] } for p in predictors.values() ]))\n",
    "Instance.build_instance_hashes(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f1  predictor\n",
      "0  0.557143  mrqa_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of errudite.predictors.qa.mrqa_allennlp.mrqa_predictor failed: Traceback (most recent call last):\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"../errudite/predictors/qa/mrqa_allennlp/mrqa_predictor.py\", line 7, in <module>\n",
      "    class MRQAPredictor(AllenPredictor):\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/allennlp/common/registrable.py\", line 49, in add_subclass_to_registry\n",
      "    raise ConfigurationError(message)\n",
      "allennlp.common.checks.ConfigurationError: 'Cannot register mrqa_predictor as Predictor; name already in use for MRQAPredictor'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for predictor in predictors.values():\n",
    "    predictor.evaluate_performance(instances)\n",
    "print(pd.DataFrame([ {\"predictor\": p.name, \"f1\": p.perform[\"f1\"] } for p in predictors.values() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([ {\"predictor\": p.name, \"f1\": p.perform[\"f1\"] } for p in predictors.values() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FOLDER = normalize_file_path(\"~/datasets/raw_data/mrqa/trains\")\n",
    "sample_size=100\n",
    "file_path = \",\".join(glob.glob(os.path.join(DATASET_FOLDER, \"*.jsonl.gz\"))[:2])\n",
    "reader.count_vocab_freq(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
